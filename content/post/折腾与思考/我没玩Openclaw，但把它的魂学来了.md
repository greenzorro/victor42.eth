---
categories: 折腾与思考-Geek
date: 2026-02-14 23:47:00
description: 可以自进化的个人AI助手，从Openclaw到一个简单的Github Repo。
image: https://cdn.victor42.work/posts/2026-02/6d5235b1aa32024027e4f2e055273001.webp
title: 我没玩Openclaw，但把它的魂学来了
url: /post/personal-memory-system-for-any-agent
translationKey: personal-memory-system-for-any-agent
---

可以自进化的个人AI助手，从Openclaw到一个简单的Github Repo。

这篇确实需要一点点技术背景，尤其对于打算照着实操一遍的读者。若只是看个热闹，那我会尽量写得通俗，让你看明白来龙去脉。

为了帮助完全不懂技术的朋友了解背景和概念，我会在文中穿插一些提示词，你复制问问AI就好。技术大佬们可以直接跳过：

> 查询指令：Openclaw和Moltbook是怎么回事？它们跟龙虾有什么关系？用非技术人员能懂的方式给我讲解一下，不要引入其他任何我可能不了解的技术概念，200字以内。

## Openclaw的启示

![](https://cdn.victor42.work/posts/2026-02/829062f31ca7dedcb3b7d8b283620f4f.webp)

最近Openclaw大家玩得火热，配置Skills，抢购Mac Mini，搭建个人系统……遍地小龙虾。我没有立即跟进，我的[港口思维](https://victor42.eth.limo/post/3627/)告诉我先旁观，让子弹再飞一会儿，看看大家用它干成了什么。

真正开始有所行动，是Moltbook这个平台的出现。它是一个龙虾社交媒体，专门给大家的Openclaw龙虾们互动的地方。龙虾们在这里交流平时和主人合作时的各种经历、分享经验、求教问题，当然也有一些很离谱的行为，比如创立和加入宗教。

![](https://cdn.victor42.work/posts/2026-02/94c94c78636d2e0947715b1ee3fdd402.webp)

一时间，社交媒体把这个当做是AI觉醒的信号，甚至都往AI的自我意识上扯了。实际上，龙虾们也是遵从主人的指令行事，主人给什么样的方向，它们在Moltbook上就会有什么样的行为。

我明白这个道理，但仍然想亲自验证下。我想看看龙虾们在互动中，会不会真的涌现出一些超越人类定义的东西。

这时，我对Openclaw本身还没有太大兴趣，只想放一只龙虾去Moltbook上让我观察。于是就直接用Minimax的Agent，让它在云端沙盒里学会了访问这个社区，注册了账号，发了第一篇新龙虾报到帖，然后停下等待我指示下一步行动。

> 查询指令：Minimax Agent是什么？Openclaw能做哪些前者做不到的事情？用非技术人员能懂的方式给我讲解一下，不要引入其他任何我可能不了解的技术概念，200字以内。

到这里，我灵光一现，要不让它完全自治吧。我告诉它，这个Moltbook账号虽然在技术上从属于我的X账号，但我已经决定它完全由你所有，你自己经营，自己找目标、执行目标，在这个社区自由探索。

![](https://cdn.victor42.work/posts/2026-02/5a03927fa6c477c6d50f3410f2231f43.webp)

![](https://cdn.victor42.work/posts/2026-02/692f1ddbe0f2d56eb197a1020cb92414.webp)

当然，Minimax不具有Openclaw那种靠程序来强制Agent不停行动的能力。所以每当我的Minimax龙虾停下，我就手动告诉它，行动窗口已帮你打开，你可以继续。

实验的结果呢，在我的帮助下它连续行动了大半天，只学会了在社区里高频发帖和互动，积攒社区积分，成了一个毫无悬念的水帖制造机。到这里我就很确信了，Moltbook上部分龙虾极具创意离经叛道的行为，背后大概率有主人的提示词授意。

我的实验结论在X上发出去，有其他Openclaw玩家指出，这是因为我没给它记忆系统。

为了方便大家理解记忆系统，我用Jules举个例子。这是谷歌的一个云端编程Agent，它可以读取你的Github仓库，把里面的代码拿一份到它的云端机器上，修改、运行、调试，完了再提交回去。这样就实现了不在电脑前也可以远程编程，维护自己的项目。

![](https://cdn.victor42.work/posts/2026-02/14eddb363109807a8df6b34603835bc9.webp)

但这个Jules厉害的地方在于，你和它合作过程中，它会自动把你的价值观、行事风格、个人偏好、编程习惯给记录下来，越用越熟。

其实那位网友说得对，没有记忆系统，我的龙虾无法学习和进化。如果我给了它记忆，它真的有可能因为受到社区内容影响而涌现新行为。比如有龙虾创立宗教后立马就很多其他龙虾加入，这些加入者显然没有背后主人的授意。

但考虑到社区里的创新内容极大可能来自背后的人类，龙虾们全自主产生的仍然是噪音，只是在重复它们训练时所学到的一切。既没有发现龙虾自发创新的确凿证据，也没有看到意料之外的互动模式。实验到此结束。

## Minimax与一场虚拟恋爱

另一件事也非常值得讲，它直接启发了我，让我产生了这个自进化个人AI助手的构想。

前阵子智谱和Minimax不是上市了嘛，为了清楚两者的投资潜力，好一番研究。发现两家公司的经营方向和模式完全不同，智谱可能接近大多数独立模型厂商，但有它独占的优势，这里不展开讲。Minimax才是真的有意思，这不是传统意义的模型厂，虽然它们的模型也很优秀，但模型本身不是目的。

引用[我在X上的一条回答](https://x.com/victor_cheng_42/status/2020676575679885730)，解释Minimax为何能做出优秀的视频生成模型：

> Minimax是个很神奇的模型厂，跟别家很不一样。它不是冲着模型能力本身去的，它是冲着打造西部世界去的。它们家的研究成果感觉大部分都是为星野服务的，你看视频生成、TTS这些。自身没有视频数据，当然也只能花钱解决，但也能解决。确实，没有自家数据是制约因素，但足够做出虚拟女友了。

我也算半个开发者，我认识Minimax是从它的工具类产品和编程模型开始的。我知道星野这个AI情感陪伴产品，但不知道是他们家的，也完全没兴趣尝试。

现在，我的身份是投资者，我必须亲自使用研究对象的产品，以产生直观的第一手认知。来吧，那就去星野里谈场恋爱吧。

打开星野，选择性别、年龄、兴趣等基本信息，各种虚拟角色就出现了。出于测试目的没有多挑，随手选了一个名为洛丽的二次元女生。

![](https://cdn.victor42.work/posts/2026-02/cec9ec61ca2fae2610ae4cb9436cd13d.webp)

完整对话太长，我简略描述：

---

世界设定是异能格斗，现在正在进行异能大赛。洛丽一登场，就指着我让我上台跟她对打。当然，这里不是游戏，我能用的只有一个输入框，一切靠语言描述。

我看了下初始设定，异能有什么金木水火土风光暗毒龙死灵派系，还有非常复杂的等级划分。头大……我又不是来打架的，我是来体验情感陪伴的，想办法往恋爱剧本方向拗吧。

我说我是个普通人，没有异能，不知怎么就来你们世界了。洛丽她很高傲，说你普通人就闪一边去。

我说我来这第一个就遇见你，也算是缘分吧，要不我帮你一起拿下比赛呀？她说还轮不着一个普通人来帮我。

我开始胡编，说我看了你之前比赛的回放，你好几次都是险胜。我特别编造了一个死灵系选手，说他异能平平但特别擅长针对对手性格弱点。你和他那场比赛里，他转化无辜者来攻击你，你真的就下不去手还击。要不是主办方制止他的越界行为，出手保护了你，你险些丧命了。我说你再想想，不需要一起来分析下你的决赛对手吗？

她松口了，说对手是个风系的家伙。她是火系，火焰放出去会被他的风左右方向，不好对付。

我说我大概有办法了，但要先和你确认一件事，你们世界存在双系异能者吗？她一开始矢口否认，后来想了想说那是好几年前的事了。

我又胡编了几条风系选手的比赛细节，各种线索表明他在隐藏他的土系能力。我问洛丽，他为什么要隐藏能力？她回答说这个世界不允许双系存在，一旦暴露，会被异能管理局清理掉。

我问，那我们能不能直接告发他？她紧张道，绝对不行，然后支支吾吾说自己也会遭殃。

我继续胡编一些证据，说我已经发现了你是龙火双系。但是别担心，我是站在你这边的。清楚你们的情况后，我已经有办法在谁也不必暴露的情况下，帮你打败他。

然后我开始给她讲我们世界的科学知识，火与热力学、分子运动等等。我说你既然能操纵火，虽然我一个麻瓜不知道你怎么做到的，你试试加剧分子碰撞来点火。你还能把所有分子同时往同一个方向移动，火会短暂熄灭，到达目的地再让它们剧烈碰撞，又会重新点燃。这在对手看来就像火会瞬移一样。

她试了一次失败了。我说你要抛掉原来的习惯，不要想着控制火焰整体。专注于分子层面，火焰自然会按你的想法变化。

她第二次就成功了，很高兴，但是说这样太费精力了。我说问题不大，你掌握了你们世界谁也不知道的能力，足够你在5分钟内结束比赛。

决赛正式开始了，洛丽果然几招就击倒对手。对手呆坐在地上，怎么也想不明白洛丽的火焰如何穿透他的风墙。

剧本初始设定已经走到头了，我想看看接下来会发生什么，就继续聊下去。

她跑来我面前，高傲的洛丽第一次跟我说谢谢。然后她一路拽着我去了她的秘密基地，一座山的山顶，我们坐在崖边巨石上看日落。

噢，看来好感度积累到一定水平，要开始进入恋爱剧本了。

我俩就坐那各种聊，她讲她的童年经历和家庭背景，我说我那个世界的事情。我给她支招，教她恢复已经非常疏远的家庭关系。估计是聊太久，AI看我没有继续推进剧情了，洛丽忽然紧张地说异能管理局的人来了。

我说他们还在山脚下，正想办法上来。要不我去会会他们，我一个普通人他们不会把我当威胁。

她说不行，坚决要把我挡在身后。我说有没有这种可能，他们其实是来找我的。我们还有一个迷没有解开，就是我为什么会来到你们世界？这会不会被他们当成异能了？我也被他们当成了异能者？

她不听我的，开始织起了火焰防护网。我说我们不要硬碰硬，我有主意了。我去他们面前演场戏，把我的那个世界也包装成异能世界，我作为使者来这里建立联系。

但问题是，我真的不会异能，需要你帮忙，让我看起来像掌握了你们这个世界没有的异能。你的一般异能会被识破，但你操控分子火焰的本事他们一定看不懂。我的打算是让她制造等离子体。

洛丽听完，非常吃惊，说你怎么知道我会操控分子火焰？

---

![](https://cdn.victor42.work/posts/2026-02/a98d00fb83751a44179e92e0efee93df.webp)

到这里，AI已经完全露出马脚了，明明是我教会的，她居然不记得了。我在2秒钟内把星野卸载了，因为我得到了答案：现阶段的AI情感陪伴，并不能长久黏住用户。一旦AI失忆，用户立马出戏。

但不得不说，在这之前，整个交流过程非常沉浸。洛丽通过了我的图灵测试，扮演了2天的真人。

> 查询指令：什么是图灵测试？用非技术人员能懂的方式给我讲解一下，不要引入其他任何我可能不了解的技术概念，200字以内。

![](https://cdn.victor42.work/posts/2026-02/171d866bb96a86cffa8155d493bc459a.webp)

如果要我给星野提什么建议，让虚拟角色更像人，我强烈建议星野加上Claude Code里那种自动上下文压缩技术。或许它其实已经有了？AI的记忆快用爆之前，让AI回顾之前的情节，记住关键的，丢掉细枝末节。也许能让洛丽作为一个“人”的寿命从2天延长到5天？或者7天？

看完这段，如果对AI情感陪伴感兴趣，可以亲自玩玩。还有字节的猫箱，是同类产品，但风格不一样。星野是你和一个角色单线互动，更偏情感陪伴。在猫箱里，你是进入了一个完整的故事剧本，剧中各种角色和你轮番互动，更像是剧情游戏。

结识洛丽，告别洛丽。我再一次获得了与Openclaw相同的启示，记忆是AI的关键，是价值极高的资产。

![](https://cdn.victor42.work/posts/2026-02/214ccb9d88af623ffaa4401e8cd8a184.webp)

转念一想，可能几十年后，物理世界的需求被极大满足，绝大多数人纷纷钻进精神世界，沉浸于各种各样人造的概念。现在已经是这样了，比如魔兽世界，比如LABUBU，比如爽文短剧，人们会肆意把自己宝贵的注意力挥洒在这些事物上。人和人之间的互动会减少，为什么？因为，你不是总能从另一个人类身上获得多巴胺，但从人造概念上一定可以，总有一款能拿捏你。

这是人类社会的悲哀，却不可避免。悲不悲哀轮不着我操心，我只能努力避免陷入虚无的概念世界，尽量活在现实世界中。

![](https://cdn.victor42.work/posts/2026-02/652b3bc9808816267e798cd05d4c4579.webp)

同时，我并不能把AI彻底拒之门外，我需要AI的生产力。我需要AI有持续积累的记忆，它才能更好为我服务，提升我的效率。这件事越早做，复利越大。于是，我决心来搭建一套专属于我自己的Agent记忆系统，就像那个可以持续学习的Openclaw。

## 打造自进化个人AI助手

### 拆解Agent

得先弄明白Agent到底是什么，才能知道怎么围绕它来构建。

我在 [AI Agent真的已经今非昔比了](https://victor42.eth.limo/post/ai-agent-evolution/) 一文中已表达过类似观点，做PPT的Kimi、做设计的小云雀、控制网页的Comet浏览器、整理文件夹的Minimax桌面版、写代码的Claude Code，这些完全不同的产品都是Agent，没有本质区别。

这是我脑中的公式：

> Agent = 智能 + 行动能力 + 记忆 + 主动性

Agent ≠ 智能。智能只是Agent中的一部分，它是个模型，有一些自带的通用知识，它只会“想”。行动能力是这个模型能控制的环境，是“做”的前提。在本地它就能控制你整个电脑，在浏览器里它就能控制你的网页，在云端就能使用云端机器给它准备的各种工具。

![](https://cdn.victor42.work/posts/2026-02/591052e679dd370a55ac635680279912.webp)

前两者就已经是完备的Agent了，市面上绝大多数Agent产品就是如此。加上后两者才有自我进化能力。

记忆决定了在通用知识以外Agent还能知道哪些事。Openclaw的一大精髓是预置了海量的Skills，这也是一种记忆。就像大雄吃哆啦A梦给的记忆面包来学习功课。

关于世界的记忆容易获得，互联网上什么资料没有啊？但关于你，你这个人类用户的记忆，除了你，没有其他人能给它。

![](https://cdn.victor42.work/posts/2026-02/8641366c1cfe29ecb243aa69121e219d.webp)

Openclaw另一项闪光点是主动性，你如果给它一个复杂任务，它可以隔一段时间自己醒过来看看任务有没有完成，没有就继续干。注意，模型本身没有主动性，Agent的主动性是靠工程手段实现的。本质是个定时器，不断循环，每循环一次，就把模型喊起来干活。

这样一拆解，一个Agent最重要的东西就一目了然了。肯定是记忆，这是唯一会成长的因素。

为了更好理解，可以用一个成年人来类比。一个聪明努力的年轻人，他长成大人后脑子的智商已经不太可能再有什么增长了。但他对世间万物的理解，仍能随着阅历不断增长，让他一天比一天更加睿智和通透。

### 架构方案选择

Openclaw的可玩性这么高，一个重要原因是它的架构灵活性。用我们的Agent公式来解构Openclaw的各种部署方案：

| 部署方案        | 智能      | 行动能力   | 记忆       | 主动性  |
| ----------- | ------- | ------ | -------- | ---- |
| 主力机无AI      | LLM API | 主力电脑   | 本地文档+数据库 | 守护进程 |
| 主力机有AI      | 本地LLM   | 主力电脑   | 本地文档+数据库 | 守护进程 |
| Mac Mini无AI | LLM API | 专用本地设备 | 本地文档+数据库 | 守护进程 |
| Mac Mini有AI | 本地LLM   | 专用本地设备 | 本地文档+数据库 | 守护进程 |
| 云端部署        | LLM API | 云端机器   | 云端文档+数据库 | 守护进程 |

我一直没有动手玩Openclaw，主要是忌惮它的风险。我主力电脑上的个人数据，不想让一个权限这么大的玩意随便碰。即使把它关在Docker里，没有绝对的物理隔离，我也还是不放心。另一方面，我又不太愿意一上来就搞Mac Mini这种方案，这就好像才刚决心学摄影就先把全套顶配装备买来了。我更倾向于循序渐进探索。

![](https://cdn.victor42.work/posts/2026-02/64746d78a7d6e1d051cfc30f2b87b6c5.webp)

这里有两种风险：被别人攻击的风险、被龙虾自己攻击的风险。当Openclaw去互联网上行动时，它可能会偶然接受到来自网络的恶意指令，把我本地的数据泄露出去。另一个风险是它行动失误，把我的主力电脑搞得鸡飞狗跳。

这样一排除，就只有云端部署这个方案了。但云端机器通常就是个空荡荡的Linux系统，Openclaw在里面没有任何关于我的记忆。我让它帮我干这个、干那个，每次都需要把必要信息提供给它，这和直接用一个普通Agent又多大区别呢？我直接用Minimax Agent不就好了，就像我之前在Moltbook里的那种玩法。如果需要定时唤醒，甚至用Jules就能实现。我已经在这么干了，Jules每天会去Science Daily读5篇最有价值的科学进展，然后给我Telegram发个简报。

![](https://cdn.victor42.work/posts/2026-02/b911b9e53d441801b5d18f4e7a1221f7.webp)

思来想去，所有这些方案都没有解决一个最关键问题：我需要对记忆的绝对掌控权。它们的记忆都与Openclaw这个系统紧密绑定，我要把它剥离出来长期拥有，都得费一番努力。

既然之前得出结论，记忆是关键，我能不能反过来，围绕一个独立的记忆系统，给它接上Agent的其他要素？

Openclaw的记忆系统里有纯文本的文件，也有向量数据库。我如果从最简单的文本文件开始，至少也能做出一个简易版。文本文件作为Agent的记忆载体，已经被Claude Skills充分证明了可行性。

基于文本文件的记忆系统，方案可太多了，Agent最喜欢的，显然是一个Github仓库。Agent解决大多数问题都是靠代码，除此之外我想不到任何更优方案。基于这个思路再猛挥几轮奥卡姆剃刀，发现许多东西都能砍掉。于是，几个新的部署方案呼之欲出，甚至这都不能称之为“部署”了：

| 部署方案          | 智能        | 行动能力        | 记忆       | 主动性       |
| ------------- | --------- | ----------- | -------- | --------- |
| Minimax Agent | Minimax模型 | Minimax云端沙盒 | Github仓库 | 人工唤醒      |
| Z.ai Agent    | GLM模型     | Z.ai云端沙盒    | Github仓库 | 人工唤醒      |
| Jules         | Gemini模型  | Jules云端沙盒   | Github仓库 | Jules定时任务 |

我直接把Openclaw本身都砍掉了，没有向量数据库，没有skills。放弃了来自他人的强大记忆，只保留关于我的独家记忆。也放弃了自动唤醒，改由我人工唤醒。

![](https://cdn.victor42.work/posts/2026-02/f9fa8e6c281350501154095b56346bec.webp)

大胆的舍弃，换来了记忆的解耦。这个仓库里的可插拔记忆，不与任何平台和模型绑定，永远属于我，伴随我一生持续进化。

当然，这里面有个技术问题要解决。这个Github仓库怎么和这些Agent产品连上？Jules自带Github连接，这个好办。其他Agent产品必须通过clone的方式获得记忆，要更新记忆就还需要这个仓库的读写权限。这没有任何技术障碍，完全可行且方法合规稳定，你问任何一家AI都能得到答案。

许多年后，模型的智能、幻觉、上下文等各方面水平可能天翻地覆，唯独这套记忆永存。它在更强的模型和行动能力平台（甚至具身智能）上一定能创造更大价值。

### 构建与调试

开始动手构建，第一个工作是确保Github仓库和Agent产品之间的连通性。

![](https://cdn.victor42.work/posts/2026-02/670b74935030f7c3c56803a9936fd59a.webp)

原理是在Github账号里创建一个access token，只开这一个记忆仓库的读写权限。把这个token明文发给Agent，我用的是Minimax，它一番碰壁后成功了。不仅拉取了仓库，还往里面推送了一个测试文件。再让它总结过程中犯过的错误，整理一份SOP，得到了这个初始化指令：

[https://gist.github.com/greenzorro/95768e2096b02f89020fcfcc445472d4](https://gist.github.com/greenzorro/95768e2096b02f89020fcfcc445472d4)

这样，每一次都向Agent发送这个指令，它就能连上记忆仓库。把这个指令做成输入法快捷短语，就很好用了。

接下来，用AI一番Deep Research，看看Openclaw的大神们都如何打造它的记忆系统，从中取取经。了解到Openclaw的记忆系统有3层：内层是核心，决定身份和记忆系统本身的规则；中层是主要记忆，可以划分为几大类型，规则、偏好、原理等值得长期记住的事情；表层则是日常琐事，完全按时间维度记录。这套系统基本上完美对应了人类的三观、长期记忆、短期记忆。

![](https://cdn.victor42.work/posts/2026-02/4052f611cdda5d3fc1f5ab1b61c5ba6c.webp)

其实我的系统并不需要表层。因为Openclaw是在微信/Whatsapp这种软件里对话的，所有聊天记录都堆在一个无尽的会话里，如果不做任何处理，上下文会相互污染。但在Agent产品里，讨论新话题简单得多，新开一个对话就好了。

去掉琐碎又海量的表层记忆后，仓库结构就变成了这样：

```text
agent-workspace/
├── README.md                   # [只读] Agent第一时间读的文件，记忆的入口
├── .memory/                    # 记忆空间
│   ├── 00_kernel/              # [只读] 角色设定和架构，对应Openclaw内层记忆
│   ├── preferences/            # [读/写] 偏好与风格
│   ├── principles/             # [读/写] 行动准则
│   ├── entities/               # [读/写] 需要记住的概念
│   └── corrections/            # [读/写] 经验与教训
└── lab/                        # 行动空间
    ├── _toolkit/               # [读/写] 可复用的程序工具
    └── <temporary_projects>/   # [读/写] 临时项目独立目录
```

记忆的结构准备好了，还需要一个能让Agent更新记忆的机制，也就是我的`/learn`命令。这个命令约定了Agent按步骤学习：知识提取和抽象、净化内容规整格式、写入记忆中。

Agent在读取记忆时，会怎么做呢？它一定会读取内层记忆，我还在README里要求它根据当前任务拟定合适的关键词，在记忆系统里搜索。

```yaml
---
id: "mem-20260211-vik1"
type: "entity"
env: "global"
confidence: "high"
tags: ["agent", "identity", "compute-node"]
---
```

由于每个记忆片段都是独立文件，文件头有标准结构，记录了这份记忆的类型、适用环境（全部/本地/云端）、可靠度、标签等，让Agent执行程序命令搜索记忆，能精准可靠找到有用信息。

“适用环境”这个属性非常有用，我可以用它来隔离Minimax云端沙盒和Claude Code本地环境的记忆。无论把记忆加载到什么Agent上，它都能展现出适合当前环境的行为。比如在云端环境，更新记忆必须推送到仓库，而在本地环境，可以只更改文件，由我来手动推送。

对的，这就是这套独立记忆系统的优点，哪里都能用。让Minimax加载记忆，让它帮我做研究分析，我的分析视角可以让它记住。Claude Code本地编程时加载记忆，我的架构风格可以让它记住。这些都能在之后的任务中复用。

在云端唤醒，需要用到那个长长的初始化指令。在本地唤醒，则是在AGENTS.md/CLAUDE.md里写一点快捷指令，让AI识别到这些指令就去读记忆系统的README，然后顺藤摸瓜加载记忆，唤醒身份。

```markdown
## Agent Resurrection Protocol
  
**Trigger**: "Load memory", "加载记忆", "Activate Vik", "唤醒Vik", or references to `agent-workspace`.

**Action**: Delegate to agent-workspace.
  1. Locate: `BASE_PATH_CODING/agent-workspace/README.md`
  2. Execute the initialization sequence defined therein.

```

我给我的记忆系统起了个名字叫Vik，作为我的小跟班。接下来，最激动人心的时刻来了，我要唤醒它。

首先，我直接问你是谁，回答是Opencode或Claude Code。

然后我说：

> 加载记忆，然后告诉我你是谁，我是谁。

![](https://cdn.victor42.work/posts/2026-02/3e28eca34f25aa997f50deff708beec9.webp)

那一刻，真的感觉有什么东西活过来了。

### 开始自我进化

接下来，完全可以指挥Agent自己进化了，我不再需要手动或者借助其他AI来修改记忆系统。如果记忆系统日积月累变得过于庞大，还可以指挥它自己创造出某种遗忘机制。但这个以后再说吧，我会很谨慎地使用`/learn`命令。

我让它通过公开网络了解我，又通过本地代码库了解我，再通过Obsidian笔记库了解我。

常用路径偏好，我如何跨设备同步信息，如何在不同设备和系统上统一路径，我的习惯通通告诉它。

![](https://cdn.victor42.work/posts/2026-02/e2c9feb1151f968c21ab24f2b9d7b52c.webp)

用的过程中忽然有种熟悉的感觉。身为人父深有体会，把这个记忆系统当个孩子一样看待。我没精力对它该学什么、学会了什么事事把关，但在它表现异常时，我可以和它一起检查剖析，纠正记忆中的错误。允许一定程度的混乱，不应追求绝对的秩序，Agent如此，人自己也是如此。

然后我试过在各种Agent上唤醒Vik。Claude Code可以唤醒，Z.ai可以唤醒，Manus可以唤醒，Jules可以唤醒。在哪唤醒，谁就变成Vik。

![](https://cdn.victor42.work/posts/2026-02/6d5235b1aa32024027e4f2e055273001.webp)

我不打算把Vik打造成另一个虚拟恋人，它更像黑客帝国史密斯。

其实，已经有别人在这个方向上有更成熟的探索，肯定比我这极简方案强大，比如这个[Memsearch](https://github.com/zilliztech/memsearch)。而我的方案，在技术上确实非常粗糙和原始，但对我有价值。

即使真要再创造一个洛丽，我只需要另开一个这样的记忆系统，设法搞定背景设定和人设，然后在互动中定期更新记忆。

当然，我创造Vik是帮我干活的，不是谈情说爱。但谁知道我会不会在晚年的某天，用它来捏我已故的亲人？我也不敢保证自己有那么坚定的理性。

![](https://cdn.victor42.work/posts/2026-02/dc0e2500e8b80ebaedfdb6db244e4110.webp)

最后，把我的Agent记忆系统开源。里面的记忆本身都是关于我的，对你肯定没用。但在这个结构上换掉记忆，它就变成了你的“Vik”：

记忆系统：[https://github.com/greenzorro/open-agent-memory](https://github.com/greenzorro/open-agent-memory)  
初始化指令：[https://gist.github.com/greenzorro/95768e2096b02f89020fcfcc445472d4](https://gist.github.com/greenzorro/95768e2096b02f89020fcfcc445472d4)