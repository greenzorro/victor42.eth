---
title: AI元认知 - 用了这么久，你真了解它吗？
description: 一篇让你醍醐灌顶的AI认知指南。
image: https://cdn.victor42.work/posts/2025-05/09dbc0f7779d7896470f8ffc876d936d.webp
date: 2025-05-22 17:50:00
categories: 折腾与思考-Geek
url: /post/do-you-really-know-ai
translationKey: do-you-really-know-ai
---

前些天受邀去前司做了一次AI相关分享，为他们团队解决业务问题。准备分享资料时，我加了一章观念性质的内容，特别针对非技术人员，希望把大家对AI的理解提到一个更高的层次，这样许多细枝末节的问题自然就会有答案。

讲完大家反响很好，表示对AI真的有全新的认识。所以把这部分单独提取出来，希望能解答更多人的困惑。

本文旨在帮助不懂技术但需要大量使用AI的人，算是个科普文。对AI行家应该没有多大帮助。

## 正确认识AI

### AI是一种什么样的智能？

分享开始前，我问了大家一个问题：“如果AI是个人，你觉得他是个什么样的人？”

你也可以尝试回答一下。

前司同事说，感觉AI是一个学习很努力的人。

然后，我基于对AI原理的了解，讲了一个比喻：AI其实像一个地牢里的作家或画家，自出生起一辈子被锁在昏暗的桌前，每日阅读如山的书籍画卷。他的寿命远超一般人，也许和整个人类文明一样老。他把世间所有记载都读完后，拿起笔，开始用文字和画来描绘这个世界。

![](https://cdn.victor42.work/posts/2025-05/09dbc0f7779d7896470f8ffc876d936d.webp)

这样一位智者知识量惊人。如果你有机会下到地牢里和他促膝长谈，他的博学会让你误以为他也有与之相称的智力，因此对他产生过高的期望和信任。

但是，真正的广博者，读万卷书也行万里路。这位地牢智者对物理世界的经验完全为零，从没用手触摸过一棵树，从没听过一声鸟鸣。他的广博知识让他能说出概念，也能正确运用，但对事物并不能形成人类这样真实和立体的理解。

就像小孩不理解死亡。

前几天女儿说：“妈妈，如果爸爸被砸死了，你不会开车，我也不会开车，谁带我们出去玩呀？”

女儿只是从爸爸妈妈嘴里听说，人死了就再也见不到了，消失不见了。但是从来没有亲密的人消失过，她一知半解。

我们的地牢智者就是这么个情况。他能回答很难的问题，是因为知识量。小孩很多常识不知道，不是比大人傻，只是因为知道得少。现在人类就是这个小孩。

另一方面，他学习和发现规律的效率远不及人。

比如训练AI的视觉能力，看过成千上万张猫的图片，他才能认识猫，能理解猫和其他毛茸茸两个耳朵的动物的区别。

而我女儿在2岁的时候，并没有见过活的鸭子。在家里和托班见到的鸭子图画，也不超过10张，她却能准确认出商场里各种鸭子造型的玩具、玩偶、游乐设施。令我吃惊的是，有次路过餐馆，她指着金黄的烤鸭说：“鸭鸭！”

![](https://cdn.victor42.work/posts/2025-05/1ab342a28441047fafc1f1fcb46dffdf.webp)

### AI为什么不听话？

另一个常见问题是，AI不按你的意图来回答。你指东，它打西。

这里可以讲一个从TED演说里听来的故事。

早在ChatGPT推出以前，人们就已经研究AI很久了。有一项研究是模拟物种演化，让AI们自己设定参数，创造出各式各样活在虚拟世界里的动物。给它们的任务是，自己在演化中不断调整参数，一轮轮比试，最终要在百米赛跑中胜出。

最后胜出的物种差不多长这样，脖子高100米，比赛开始立马倒下，直达终点：

![](https://cdn.victor42.work/posts/2025-05/0ce256e5944fbb8c825d1e21883095bd.webp)

给你5秒钟笑一会儿。

这看似是AI找到了规则漏洞，并加以利用。但它们为什么能想到这么鸡贼的办法？

其实，不是AI不听话。是人了解全部背景信息，大家在一个频道上。我们都知道，没有哪种动物是为百米赛而生的，还有许多限定条件。这种动物要能正常行动、正常觅食、正常繁衍，面对天敌要能成功逃脱不至于被吃到灭绝。这些我们都知道，且默认会考虑进来。AI也知道，但并不当回事，因为你没讲。

相比之下，AI更像供应商对接人，凡事都跟你说“好的”。你惜字如金，它乱做一气。

要AI听话，就得把它该知道的都告诉它，并指示它缺少信息要主动提问。

### AI为什么胡编？

这个术语叫“幻觉”，可能是AI使用者最大的烦恼源泉。让它做行业研究，它瞎编数字，引用不存在的文献。感觉像某个受了气准备第二天掀桌离职、此刻正在极尽报复的螺丝钉。

AI当然不会蓄意报复，它没有情绪。它只是想“帮”你。

主流的文字类AI，本质上是一个故事续写机器，它只有一种能力：接着已有的文字继续写下去。给它一个小说开头，它写出来的就是故事。给它半页合同，它写出来的就是合同条款。

但你会说，我用的AI不是这样啊，它像人一样能和我聊天。没错，通过一种巧妙的逻辑设计，可以把故事续写机变成聊天机器人。

![](https://cdn.victor42.work/posts/2025-05/47c8598d8d8102ce4ff2d1bf22f084cd.webp)

在你看来，你说的话是“你好啊，你叫什么名字？”。而AI接受到的信息也是“你好啊，你叫什么名字？”，然后给出了它的回复。

实际上，AI接受到的信息可能是这样的：

> 你是一个乐于助人的助手，你将要回答用户的问题。
> 
> 用户说：你好啊，你叫什么名字？
> 
> 助手说：

其中“你是一个乐于助人的助手，你将要回答用户的问题”这部分你看不见，固定写在程序里了，叫做系统提示词。

看见没，它不是在回答问题，而是在续写一个用户和助手相互交流的剧本。它判断助手在这个情况下可能回复什么，就把相应内容接在后面。

![](https://cdn.victor42.work/posts/2025-05/bbdb4bc32843752ad5ba33592d4959eb.webp)

如果你再回一句，这次它接收到的信息就会是这样：

> 你是一个乐于助人的助手，你将要回答用户的问题。
> 
> 用户说：你好啊，你叫什么名字？
> 
> 助手说：你好呀！我叫豆包，很开心能和你互动呢～要是你有任何问题或者需要帮忙的地方，随时跟我说哦 😊
> 
> 用户说：你可以叫我可乐，请多指教
> 
> 助手说：

它每次都会把全部历史信息带进来，确保不会离题。这样，它就能把对话一直继续下去。同时，AI工具被做成了只展示助手最新的回复内容，让你感觉像是一来一回的交流。

**那为什么这样它就会胡编呢？**

来看一个最经典、最广泛使用的简易系统提示词："You are a helpful assistant."

![](https://cdn.victor42.work/posts/2025-05/421edc7a9ebe6cf69aa23245d5d0ea01.webp)

剑桥词典对 helpful 一词的解释，其中 willing to help 是关键。我们中文里通常把这个词翻译成“有帮助”，这其实稍微窄化了原意，听起来只有被动的意思。一把有帮助的锤子，在我需要的时候我拿他来钉钉子。

但它原意还有 willing to help，原意帮助，这是主动的！显然是一个有生命、至少有智能的东西，想要去帮助别人。系统提示词给助手的定义就是这样，它想要帮助用户，它得帮助用户。

在这个前提下，严谨不是它的主要考虑，能给出一个回答（帮到用户）才是，即使不正确。况且，如果AI真的有人这样的自我意识，它也会发现自己是以第三人称视角在续写这个故事：故事里有个助手很想帮别人，还有个用户来找这个助手聊天，助手会怎么回复呢，我得给它写完整。

给出回答是第一要务，严谨性得靠边站，胡编当然就是可以接受的。

AI不同于程序，程序是精确的，AI更像人。许多非技术人员因为AI是“高科技”，而对它产生了程序般精确的期望，这是人的误解。

就像我问你：“上周二下午你在干什么？必须回答。”

你除了编还能怎么办？

当然，幻觉还有其他原因，比如训练数据本身就有问题等。但这个是根子上的原因。

幻觉无法根除。给它接入网络、让它每个结论给出具体依据、让它读知识库，都可以减少幻觉。

## AI的能力

AI既然这么多毛病，我能怎么用它呢？

文字类AI有3类能力：

1. 语言（★★★★★）：对语言（中文、外语、编程语言）本身的理解和运用。
2. 知识（★★☆☆☆）：学习语言过程中获得的世界知识。
3. 推理（★★★☆☆）：通过语言逻辑和世界知识发现的事物间的内在联系，因此产生的推理能力。

其中，知识方面，它严重偏科。如果把世间所有信息按照影响力大小、影响时间长短分到4个象限里，大概就会是这样：

![](https://cdn.victor42.work/posts/2025-05/80c737da52f381f59e34b4bd9a24dc01.webp)

AI在训练中获得的知识：几乎全部**历史**、大部分**热点、**小部分**传承**、极少**琐事**。

世界上信息这么多，AI当然选择记住那些反复被人提及的。这些都是重要的、广泛传播过的信息。开启搜索能力，AI能回答更多**热点**和**传承**类问题，但可能会降低**历史**类问题的回答质量（人类的理解未必比AI好）。

什么事该找AI？什么不该？

- ✅ 给这篇文章起一个能勾起好奇心的标题，要结合关税战话题。
- ✅ 解释个税专项附加扣除的算法。
- ✅ 敦煌5月份大概什么气温？去玩要带什么衣服？
- ❌ 这两张设计稿哪个效果更好？
- ❌ 现在是合适的入市时机吗？
- ❌ 这份简历有造假吗？

到这里，我们已经明白了，AI不能替你干所有事情。你生活工作中要解决的问题，往往由许多个小问题构成。AI能解决其中一部分，剩余得你亲自上手。用好AI，就是用它替代掉任务流程里部分环节。

![](https://cdn.victor42.work/posts/2025-05/70b708611424a7986dd304fcf733ce41.webp)

AI模型能力的迭代增强，它能稳定可靠地接管更多环节。而如果你善用AI，了解各种模型和工具的优劣势，知道它们适合处理什么问题，你还能进一步扩大AI的替代范围。

在极其复杂的任务中，AI能替代的环节不止一个。你甚至会反复经历“人工——AI——人工——AI——”这样的接力。假如没了AI这个任务无法完成，那AI显然是有价值的。如果AI的环节你用人工方式也能完成，那就要权衡一下值不值得交给AI？这是不是一个频繁出现、需要反复解决的问题？AI的加入能不能让人工投入的时间变少？

极致的例子可以看我这篇文章：[卖AI图，从开单到金盆洗手](https://victor42.eth.limo/post/automate-ai-illustrations-production/)

## 写在最后

由于是观念性质的科普文，具体问题的解决这里就不谈了。

从ChatGPT出现到现在，已经2年半了。这2年半里，我看到身边的朋友同事们逐渐开始拥抱AI，但许多人一直不得要领，对AI犯的错误束手无策。

网络上有许多AI使用技巧的教程，教工具，卖提示词。但如果跳出术的范围，从原理层面了解AI到底是个什么样的东西，该怎么看待它，你会更加游刃有余，运用自如。
