---
title: 另一种方位感
description: 我原本是不信AI有方位感的，直到……
image: 
date: 2023-03-27 14:45:00
categories: 折腾与思考
url: /post/3634
---

看微软关于GPT-4的那篇论文，其中有一个实验，研究人员虚构了一张解谜游戏的地图，包含许多房间和几条通道。他们让GPT-4来玩这个游戏，在这个世界中探索，并且最终让它画出房间和通道的地图。AI对方位的理解非常正确，画出的地图结构与研究人员预期的一致，而且每个房间的门的数量都推断正确。

我也对GPT-3.5做过类似的实验，判断它对方位的理解。当时是问了它一个地理问题，冬季傍晚，人站在故宫西南角，能不能看到故宫南墙被阳光照亮。它的推理逻辑非常正确，思考故宫在哪个半球，北半球冬季太阳从哪边落下，日落时南墙在不在阳光照射范围内。但推导过程中一个关键的方位词却答错（太阳从西北落下说成了西南），最终还是得出了正确的结论，南墙不会被照亮。

那时我对这个AI的理解，更偏统计学，认为是统计学的概率误差让它输出了错误的词（西南）。当时我觉得，它对方位并没有像人这样的理解，因为它没有物理身体，没有方位感。对于前后左右这样的概念，它完全是通过文字里的描述来理解的。比如，人类世界里有大量文字内容包含了某种方位和身体关系的模式“我看见前面有XXX”，而“我看见左/右边有XXX”出现的频率次之，“我看见后面有XXX”的频率最低。结合它对于人类身体结构和视野的知识，它就能推断出前后左右对于人意味着什么。当然，实际情况可能比这复杂，而且目前没人弄明白了它是怎么理解的。

而看了微软论文里的这个实验后，又有点刷新认知了。虽然它对方位的理解可能还是老样子，不像有身体的人可以凭本能可以感知方位，而是要用它对方位的模糊理解加上逻辑推理来感知世界，但它毕竟做到了。为什么这种基于推理的方位感知就不算方位感呢？这是另一种我们没见过的、但行之有效的方位感。

这就可以引发两点很耐人寻味的思考：

1. 怎样的理解才算是“理解”？一定要用人类的方式理解世界才算是智能吗？用更包容的心态看待“智能”这一概念，也许更有助于理解人类与AI的关系。
2. 人工智能是一种很特殊的智能，它在没有本体（自我）意识的情况下产生了对世界的理解，并演化出了推理的能力。它的信息输入输出媒介是语言，它思考的载体也是语言，能用人类语言描述的概念，它基本上就能理解，而且理解得很不错。而一些难以言表的、偏生物本能的概念，如果人也没有建立理论分析明白，那AI也无法理解，不是因为多么高深，而是语言里缺乏相应概念。
